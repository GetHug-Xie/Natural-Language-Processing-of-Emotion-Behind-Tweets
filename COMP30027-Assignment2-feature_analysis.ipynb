{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2022 Semester 1\n",
    "\n",
    "## Assignment 2: Sentiment Classification of Tweets\n",
    "\n",
    "This is a sample code to assist you with vectorising the 'Train' dataset for your assignment 2.\n",
    "\n",
    "First we read the CSV datafiles (Train and Test)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This python file chooses BoW vectorization\n",
    "### There  is another file using TFIDF vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"Train.csv\", sep=',')\n",
    "test_data = pd.read_csv(\"Test.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we separate the tweet text and the label (sentiment). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train length: 21802\n",
      "Test length: 6099\n"
     ]
    }
   ],
   "source": [
    "#separating instance and label for Train\n",
    "X_train_raw = [x[0] for x in train_data[['text']].values]\n",
    "Y_train = [x[0] for x in train_data[['sentiment']].values]\n",
    "\n",
    "#check the result\n",
    "print(\"Train length:\",len(X_train_raw))\n",
    "\n",
    "#separating instance and label for Test\n",
    "X_test_raw = [x[0] for x in test_data[['text']].values]\n",
    "\n",
    "#check the result\n",
    "print(\"Test length:\",len(X_test_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A cleaning function to get rid of words with low analyzing values\n",
    "# Keep the necessary texts only to make the analysis efficient and reliable\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "import unidecode\n",
    "from word2number import w2n\n",
    "import contractions\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "# exclude words from spacy stopwords list\n",
    "deselect_stop_words = ['no', 'not']\n",
    "for w in deselect_stop_words:\n",
    "    nlp.vocab[w].is_stop = False\n",
    "\n",
    "\n",
    "def strip_html_tags(text):\n",
    "    \"\"\"remove html tags from text\"\"\"\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    stripped_text = soup.get_text(separator=\" \")\n",
    "    return stripped_text\n",
    "\n",
    "\n",
    "def remove_whitespace(text):\n",
    "    \"\"\"remove extra whitespaces from text\"\"\"\n",
    "    text = text.strip()\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "\n",
    "def remove_accented_chars(text):\n",
    "    \"\"\"remove accented characters from text, e.g. café\"\"\"\n",
    "    text = unidecode.unidecode(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def expand_contractions(text):\n",
    "    \"\"\"expand shortened words, e.g. don't to do not\"\"\"\n",
    "    text = contractions.fix(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def text_preprocessing(text, accented_chars=True, contractions=True, \n",
    "                       convert_num=True, extra_whitespace=True, \n",
    "                       lemmatization=True, lowercase=True, punctuations=True,\n",
    "                       remove_html=True, remove_num=True, special_chars=True, \n",
    "                       stop_words=True):\n",
    "    \"\"\"preprocess text with default option set to true for all steps\"\"\"\n",
    "    if remove_html == True: #remove html tags\n",
    "        text = strip_html_tags(text)\n",
    "    if extra_whitespace == True: #remove extra whitespaces\n",
    "        text = remove_whitespace(text)\n",
    "    if accented_chars == True: #remove accented characters\n",
    "        text = remove_accented_chars(text)\n",
    "    if contractions == True: #expand contractions\n",
    "        text = expand_contractions(text)\n",
    "    if lowercase == True: #convert all characters to lowercase\n",
    "        text = text.lower()\n",
    "\n",
    "    doc = nlp(text) #tokenise text\n",
    "\n",
    "    clean_text = []\n",
    "    \n",
    "    for token in doc:\n",
    "        flag = True\n",
    "        edit = token.text\n",
    "        # remove stop words\n",
    "        if stop_words == True and token.is_stop and token.pos_ != 'NUM': \n",
    "            flag = False\n",
    "        # remove punctuations\n",
    "        if punctuations == True and token.pos_ == 'PUNCT' and flag == True: \n",
    "            flag = False\n",
    "        # remove special characters\n",
    "        if special_chars == True and token.pos_ == 'SYM' and flag == True: \n",
    "            flag = False\n",
    "        # remove numbers\n",
    "        if remove_num == True and (token.pos_ == 'NUM' or token.text.isnumeric()) \\\n",
    "        and flag == True:\n",
    "            flag = False\n",
    "        # convert number words to numeric numbers\n",
    "        if convert_num == True and token.pos_ == 'NUM' and flag == True:\n",
    "            edit = w2n.word_to_num(token.text)\n",
    "        # convert tokens to base form\n",
    "        elif lemmatization == True and token.lemma_ != \"-PRON-\" and flag == True:\n",
    "            edit = token.lemma_\n",
    "        # append tokens edited and not removed to list \n",
    "        if edit != \"\" and flag == True:\n",
    "            clean_text.append(edit)        \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\643944.STUDENT\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Use the function defined above to clean X_train_raw and X_test_raw\n",
    "\n",
    "X_train_clean = []\n",
    "for curr_text in X_train_raw:\n",
    "    cleaned_text = text_preprocessing(curr_text, accented_chars=True, contractions=True, \n",
    "                       convert_num=True, extra_whitespace=True, \n",
    "                       lemmatization=True, lowercase=True, punctuations=True,\n",
    "                       remove_html=True, remove_num=True, special_chars=True, \n",
    "                       stop_words=True)\n",
    "    X_train_clean.append(\" \".join(cleaned_text))\n",
    "    \n",
    "X_test_clean = []\n",
    "for curr_text in X_test_raw:\n",
    "    cleaned_text = text_preprocessing(curr_text, accented_chars=True, contractions=True, \n",
    "                       convert_num=True, extra_whitespace=True, \n",
    "                       lemmatization=True, lowercase=True, punctuations=True,\n",
    "                       remove_html=True, remove_num=True, special_chars=True, \n",
    "                       stop_words=True)\n",
    "    X_test_clean.append(\" \".join(cleaned_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is anybody going to the radio station tomorrow to see shawn? me and my friend may go but we would like to make new friends/meet there (:\t\n",
      "anybody go radio station tomorrow shawn friend like new friend meet (:\n",
      " if putin wanted to intervene all he would have had to do is donate to the clinton foundation. not hack computers &‚ä¶ https://t.co/2wuck3zowg\n",
      "putin want intervene donate clinton foundation not hack computer & ap https://t.co/2wuck3zowg\n"
     ]
    }
   ],
   "source": [
    "#Let's see one example tweet\n",
    "print(X_train_raw[1])\n",
    "print(X_train_clean[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# the ratio of test_data on train_data is approximately 0.28\n",
    "X_sub_train, X_valid, Y_sub_train, Y_valid = train_test_split(X_train_clean, Y_train, test_size=0.28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This python file chooses BoW vectorization\n",
    "### There  is another file using TFIDF vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bag of Words (BoW)\n",
    "In this approach, we use the **CountVectorizer** library to separate all the words in the Train corpus (dataset). These words are then used as the 'vectors' or 'features' to represent each instance (Tweet) in `Train` and `Test` datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train feature space size (using BoW): (15697, 118531)\n",
      "Validation feature space size (using BoW): (6105, 118531)\n",
      "Test feature space size (using BoW): (6099, 118531)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# count the words in group of 2\n",
    "BoW_vectorizer = CountVectorizer(analyzer='word', ngram_range=(2,2))\n",
    "\n",
    "#Build the feature set (vocabulary) and vectorise the Tarin dataset using BoW\n",
    "X_train_BoW = BoW_vectorizer.fit_transform(X_sub_train)\n",
    "X_valid_BoW = BoW_vectorizer.transform(X_valid)\n",
    "\n",
    "#Use the feature set (vocabulary) from Train to vectorise the Test dataset \n",
    "X_test_BoW = BoW_vectorizer.transform(X_test_clean)\n",
    "\n",
    "print(\"Train feature space size (using BoW):\",X_train_BoW.shape)\n",
    "print(\"Validation feature space size (using BoW):\",X_valid_BoW.shape)\n",
    "print(\"Test feature space size (using BoW):\",X_test_BoW.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now each row is a list of tuples with the vector_id (word_id in the vocabulary) and the number of times it repeated in that given instance (tweet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 107719)\t1\n",
      "  (0, 115231)\t1\n",
      "  (0, 81080)\t1\n",
      "  (0, 111796)\t1\n",
      "  (0, 51826)\t1\n",
      "  (0, 111843)\t1\n",
      "  (0, 87553)\t1\n",
      "  (0, 111918)\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'anybody go radio station tomorrow shawn friend like new friend meet (:'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's see one example tweet using the BoW feature space\n",
    "print(X_train_BoW[1])\n",
    "X_train_clean[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the created vocabulary for the given dataset in a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dict = BoW_vectorizer.vocabulary_\n",
    "# output_pd = pd.DataFrame(list(output_dict.items()),columns = ['word','count'])\n",
    "\n",
    "# output_pd.T.to_csv('BoW-vocab.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. TFIDF\n",
    "In this approach, we use the **TfidfVectorizer** library to separate all the words in this corpus (dataset). Same as the BoW approach, these words are then used as the 'vectors' or 'features' to represent each instance (Tweet).\n",
    "\n",
    "However, in this method for each instance the value associated with each 'vector' (word) is not the number of times the word repeated in that tweet, but the TFIDF value of then 'voctor' (word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train feature space size (using TFIDF): (15697, 30654)\n",
      "Validation feature space size (using TFIDF): (6105, 30654)\n",
      "Test feature space size (using TFIDF): (6099, 30654)\n"
     ]
    }
   ],
   "source": [
    "# Change name only for further tests, named BoW but tfidf indeed!\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "#Build the feature set (vocabulary) and vectorise the Tarin dataset using TFIDF\n",
    "X_train_BoW = tfidf_vectorizer.fit_transform(X_sub_train)\n",
    "X_valid_BoW = tfidf_vectorizer.transform(X_valid)\n",
    "\n",
    "#Use the feature set (vocabulary) from Train to vectorise the Test dataset \n",
    "X_test_BoW = tfidf_vectorizer.transform(X_test_clean)\n",
    "\n",
    "print(\"Train feature space size (using TFIDF):\",X_train_BoW.shape)\n",
    "print(\"Validation feature space size (using TFIDF):\",X_valid_BoW.shape)\n",
    "print(\"Test feature space size (using TFIDF):\",X_test_BoW.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1877)\t0.3139828051017137\n",
      "  (0, 12657)\t0.07338243398111931\n",
      "  (0, 2538)\t0.13339040558232085\n",
      "  (0, 15942)\t0.20684974486187413\n",
      "  (0, 3774)\t0.2793780223458861\n",
      "  (0, 2723)\t0.22975078437456284\n",
      "  (0, 15944)\t0.30121120940241425\n",
      "  (0, 13640)\t0.1880449577623256\n",
      "  (0, 2093)\t0.2632877146742299\n",
      "  (0, 1683)\t0.23705221780985478\n",
      "  (0, 8231)\t0.3139828051017137\n",
      "  (0, 1965)\t0.21196886860278757\n",
      "  (0, 17792)\t0.3139828051017137\n",
      "  (0, 15722)\t0.20154741294775103\n",
      "  (0, 6521)\t0.2602855745192658\n",
      "  (0, 24267)\t0.3139828051017137\n",
      "  (0, 6020)\t0.0628719058199213\n"
     ]
    }
   ],
   "source": [
    "#Let's see one example tweet using the TFIDF feature space\n",
    "print(X_train_tfidf[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15697, 11197)\n",
      "(6105, 11197)\n",
      "(6099, 11197)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(threshold=0.0001)\n",
    "X_var_train = selector.fit_transform(X_train_BoW)\n",
    "print(X_var_train.shape)\n",
    "X_var_valid = selector.transform(X_valid_BoW)\n",
    "print(X_var_valid.shape)\n",
    "X_var_test = selector.transform(X_test_BoW)\n",
    "print(X_var_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0-R Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.5795374912403644\n",
      "Validation accuracy:  0.5834561834561834\n"
     ]
    }
   ],
   "source": [
    "# Baseline model: Dummy Classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = DummyClassifier(strategy='most_frequent')\n",
    "model = clf.fit(X_var_train, Y_sub_train)\n",
    "\n",
    "Y_train_predicted = model.predict(X_var_train)\n",
    "print('Training accuracy: ', np.mean(Y_train_predicted == Y_sub_train))\n",
    "\n",
    "lr_acc = np.mean(cross_val_score(model, X_var_valid, Y_valid, cv=5))\n",
    "print('Validation accuracy: ', lr_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.810409632413837\n",
      "Validation accuracy:  0.6036036036036037\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(solver='sag', multi_class='multinomial',C=0.8, max_iter=200).fit(X_var_train, Y_sub_train)\n",
    "\n",
    "Y_train_predicted = lr.predict(X_var_train)\n",
    "print('Training accuracy: ', np.mean(Y_train_predicted == Y_sub_train))\n",
    "\n",
    "lr_acc = np.mean(cross_val_score(lr, X_var_valid, Y_valid, cv=5))\n",
    "print('Validation accuracy: ', lr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_label = lr.predict(X_var_test)\n",
    "kaggle_label = {\"id\": test_data.id, \"sentiment\": LR_label}\n",
    "\n",
    "output_pd = pd.DataFrame(kaggle_label)\n",
    "output_pd.to_csv('Prototype.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.8150602025864815\n",
      "Validation accuracy:  0.5873873873873874\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='linear', C=0.8).fit(X_var_train, Y_sub_train)\n",
    "\n",
    "Y_train_predicted = svm.predict(X_var_train)\n",
    "print('Training accuracy: ', np.mean(Y_train_predicted == Y_sub_train))\n",
    "\n",
    "svm_acc = np.mean(cross_val_score(svm, X_var_valid, Y_valid, cv=5))\n",
    "print('Validation accuracy: ', svm_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.6113907116009428\n",
      "Validation accuracy:  0.5821457821457822\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='poly',degree=3, C=0.1).fit(X_var_train, Y_sub_train)\n",
    "\n",
    "Y_train_predicted = svm.predict(X_var_train)\n",
    "print('Training accuracy: ', np.mean(Y_train_predicted == Y_sub_train))\n",
    "\n",
    "svm_acc = np.mean(cross_val_score(svm, X_var_valid, Y_valid, cv=5))\n",
    "print('Validation accuracy: ', svm_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\643944.STUDENT\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\643944.STUDENT\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\643944.STUDENT\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 255, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\Users\\643944.STUDENT\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 342, in _sparse_fit\n",
      "    kernel_type = self._sparse_kernels.index(kernel)\n",
      "ValueError: 'sigmod' is not in list\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\643944.STUDENT\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.60482891 0.57870929 0.5845704         nan 0.58106592 0.60049714\n",
      " 0.58590788        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'C':[0.1, 1], 'kernel':('linear', 'rbf', 'poly', 'sigmod')}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(X_var_train, Y_sub_train)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.6234949353379626\n",
      "Validation accuracy:  0.5993447993447993\n"
     ]
    }
   ],
   "source": [
    "# using the optimal set of parameters\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='linear', C=0.1).fit(X_var_train, Y_sub_train)\n",
    "\n",
    "Y_train_predicted = svm.predict(X_var_train)\n",
    "print('Training accuracy: ', np.mean(Y_train_predicted == Y_sub_train))\n",
    "\n",
    "svm_acc = np.mean(cross_val_score(svm, X_var_valid, Y_valid, cv=5))\n",
    "print('Validation accuracy: ', svm_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.585462190227432\n",
      "Validation accuracy:  0.5847665847665848\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf_rf = RandomForestClassifier(criterion = 'entropy', max_depth = 12, max_features = 'auto',\n",
    "    min_samples_leaf = 1, min_samples_split = 3, n_estimators = 100, random_state = 6)\n",
    "clf_rf.fit(X_var_train, Y_sub_train)\n",
    "\n",
    "Y_train_predicted = clf_rf.predict(X_var_train)\n",
    "print('Training accuracy: ', np.mean(Y_train_predicted == Y_sub_train))\n",
    "\n",
    "clf_rf_acc = np.mean(cross_val_score(clf_rf, X_var_valid, Y_valid, cv=5))\n",
    "print('Validation accuracy: ', clf_rf_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.5795374912403644\n",
      "Validation accuracy:  0.5834561834561834\n"
     ]
    }
   ],
   "source": [
    "rand_clf = RandomForestClassifier(\n",
    "    criterion = 'entropy',\n",
    "    max_depth = 10,\n",
    "    max_features = 'log2',\n",
    "    min_samples_leaf = 1,\n",
    "    min_samples_split = 5,\n",
    "    n_estimators = 90,\n",
    "    random_state = 6,\n",
    ")\n",
    "rand_clf.fit(X_var_train, Y_sub_train)\n",
    "\n",
    "Y_train_predicted_rf = rand_clf.predict(X_var_train)\n",
    "print('Training accuracy: ', np.mean(Y_train_predicted_rf == Y_sub_train))\n",
    "\n",
    "clf_rf_acc = np.mean(cross_val_score(rand_clf, X_var_valid, Y_valid, cv=5))\n",
    "print('Validation accuracy: ', clf_rf_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [134]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m rf_grid_param \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m80\u001b[39m,\u001b[38;5;241m90\u001b[39m,\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m110\u001b[39m,\u001b[38;5;241m120\u001b[39m],\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgini\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentropy\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_features\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m }\n\u001b[0;32m     10\u001b[0m grid_search_rf \u001b[38;5;241m=\u001b[39m GridSearchCV(clf_rf, rf_grid_param, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mgrid_search_rf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_var_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_sub_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m grid_search_rf\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1391\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1392\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    835\u001b[0m         )\n\u001b[0;32m    836\u001b[0m     )\n\u001b[1;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    860\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:702\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    699\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    701\u001b[0m fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m--> 702\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m \u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    703\u001b[0m score_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m-\u001b[39m fit_time\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:761\u001b[0m, in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[0;32m    759\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test)\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 761\u001b[0m         scores \u001b[38;5;241m=\u001b[39m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    763\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m error_score \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:418\u001b[0m, in \u001b[0;36m_passthrough_scorer\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_passthrough_scorer\u001b[39m(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;124;03m\"\"\"Function that wraps estimator.score\"\"\"\u001b[39;00m\n\u001b[1;32m--> 418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator\u001b[38;5;241m.\u001b[39mscore(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:651\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[38;5;124;03m    Mean accuracy of ``self.predict(X)`` wrt. `y`.\u001b[39;00m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m--> 651\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:808\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    790\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 808\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    811\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:861\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    856\u001b[0m all_proba \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    857\u001b[0m     np\u001b[38;5;241m.\u001b[39mzeros((X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], j), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    858\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39matleast_1d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_)\n\u001b[0;32m    859\u001b[0m ]\n\u001b[0;32m    860\u001b[0m lock \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mLock()\n\u001b[1;32m--> 861\u001b[0m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_joblib_parallel_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequire\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msharedmem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_accumulate_prediction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimators_\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m proba \u001b[38;5;129;01min\u001b[39;00m all_proba:\n\u001b[0;32m    871\u001b[0m     proba \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:640\u001b[0m, in \u001b[0;36m_accumulate_prediction\u001b[1;34m(predict, X, out, lock)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_accumulate_prediction\u001b[39m(predict, X, out, lock):\n\u001b[0;32m    634\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;124;03m    This is a utility function for joblib's Parallel.\u001b[39;00m\n\u001b[0;32m    636\u001b[0m \n\u001b[0;32m    637\u001b[0m \u001b[38;5;124;03m    It can't go locally in ForestClassifier or ForestRegressor, because joblib\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;124;03m    complains that it cannot pickle it when placed there.\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 640\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m lock:\n\u001b[0;32m    642\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:972\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.predict_proba\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    970\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    971\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X, check_input)\n\u001b[1;32m--> 972\u001b[0m proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    975\u001b[0m     proba \u001b[38;5;241m=\u001b[39m proba[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_]\n",
      "File \u001b[1;32msklearn\\tree\\_tree.pyx:753\u001b[0m, in \u001b[0;36msklearn.tree._tree.Tree.predict\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msklearn\\tree\\_tree.pyx:758\u001b[0m, in \u001b[0;36msklearn.tree._tree.Tree.predict\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\scipy\\sparse\\_base.py:119\u001b[0m, in \u001b[0;36mspmatrix.get_shape\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    116\u001b[0m     new_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreshape(shape, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39masformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat)\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m new_matrix\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_shape\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;124;03m\"\"\"Get shape of a matrix.\"\"\"\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# take very long time!!!\n",
    "\n",
    "rf_grid_param = {\n",
    "    \"n_estimators\": [80,90,100,110,120],\n",
    "    \"criterion\": ['gini', 'entropy'],\n",
    "    'max_depth': range(1,20,2),\n",
    "    'min_samples_leaf': range(1,10,1),\n",
    "    'min_samples_split': range(2,10,1),\n",
    "    'max_features': ['auto','log2']\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(clf_rf, rf_grid_param, cv=5)\n",
    "grid_search_rf.fit(X_var_train, Y_sub_train)\n",
    "\n",
    "grid_search_rf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time of 0-R Baseline model classifier: 0.012 s\n",
      "Training accuracy:  0.5795374912403644\n",
      "Validation accuracy:  0.5834561834561834\n",
      "Macro Precision: 0.194485\n",
      "Macro Recall: 0.333333\n",
      "Macro F1 score: 0.245647\n",
      "Weighted Precision: 0.340421\n",
      "Weighted Recall: 0.583456\n",
      "Weighted F1 score: 0.429972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\643944.STUDENT\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\643944.STUDENT\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Baseline model: Dummy Classifier\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# record time start running the model\n",
    "t0 = time.time()\n",
    "\n",
    "# 0-R Baseline model\n",
    "baseline = DummyClassifier(strategy='most_frequent').fit(X_var_train, Y_sub_train)\n",
    "\n",
    "# record time finished then minus the initial time to get the time consumed\n",
    "t1 = time.time() - t0\n",
    "print(\"Execution time of 0-R Baseline model classifier: {} s\".format(round(t1,3)))\n",
    "\n",
    "Y_train_predicted = baseline.predict(X_var_train)\n",
    "print('Training accuracy: ', np.mean(Y_train_predicted == Y_sub_train))\n",
    "\n",
    "baseline_acc = np.mean(cross_val_score(baseline, X_var_valid, Y_valid, cv=5))\n",
    "print('Validation accuracy: ', baseline_acc)\n",
    "\n",
    "# baseline_label = baseline.predict(X_var_test)\n",
    "# print(baseline_label.shape)\n",
    "\n",
    "Y_valid_predicted = baseline.predict(X_var_valid)\n",
    "\n",
    "# Compute Macro metrics of the classifier\n",
    "precision = precision_score(Y_valid, Y_valid_predicted, average = 'macro')\n",
    "print('Macro Precision: %f' % precision)\n",
    "\n",
    "# Recall = TP / (TP + FN)\n",
    "recall = recall_score(Y_valid, Y_valid_predicted, average = 'macro')\n",
    "print('Macro Recall: %f' % recall)\n",
    "\n",
    "# F1 = 2 TP / (2 TP + FP + FN)\n",
    "f1 = f1_score(Y_valid, Y_valid_predicted, average = 'macro')\n",
    "print('Macro F1 score: %f' % f1)\n",
    "\n",
    "# Compute Weighted metrics of the classifier\n",
    "precision = precision_score(Y_valid, Y_valid_predicted, average = 'weighted')\n",
    "print('Weighted Precision: %f' % precision)\n",
    "recall = recall_score(Y_valid, Y_valid_predicted, average = 'weighted')\n",
    "print('Weighted Recall: %f' % recall)\n",
    "f1 = f1_score(Y_valid, Y_valid_predicted, average = 'weighted')\n",
    "print('Weighted F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time of logistic regression classifier: 0.615 s\n",
      "Training accuracy:  0.810409632413837\n",
      "Validation accuracy:  0.6036036036036037\n",
      "Macro Precision: 0.551143\n",
      "Macro Recall: 0.432154\n",
      "Macro F1 score: 0.437308\n",
      "Weighted Precision: 0.584000\n",
      "Weighted Recall: 0.608845\n",
      "Weighted F1 score: 0.555383\n"
     ]
    }
   ],
   "source": [
    "# Multinominal Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# record time start running the model\n",
    "t0 = time.time()\n",
    "\n",
    "# Logestic Regression\n",
    "lr = LogisticRegression(solver='sag', multi_class='multinomial',C=0.8, max_iter=200).fit(X_var_train, Y_sub_train)\n",
    "\n",
    "# record time finished then minus the initial time to get the time consumed\n",
    "t1 = time.time() - t0\n",
    "print(\"Execution time of logistic regression classifier: {} s\".format(round(t1,3)))\n",
    "\n",
    "Y_train_predicted = lr.predict(X_var_train)\n",
    "print('Training accuracy: ', np.mean(Y_train_predicted == Y_sub_train))\n",
    "\n",
    "lr_acc = np.mean(cross_val_score(lr, X_var_valid, Y_valid, cv=5))\n",
    "print('Validation accuracy: ', lr_acc)\n",
    "\n",
    "LR_label = lr.predict(X_var_test)\n",
    "Y_valid_predicted = lr.predict(X_var_valid)\n",
    "\n",
    "# Compute Macro metrics of the classifier\n",
    "precision = precision_score(Y_valid, Y_valid_predicted, average = 'macro')\n",
    "print('Macro Precision: %f' % precision)\n",
    "\n",
    "# Recall = TP / (TP + FN)\n",
    "recall = recall_score(Y_valid, Y_valid_predicted, average = 'macro')\n",
    "print('Macro Recall: %f' % recall)\n",
    "\n",
    "# F1 = 2 TP / (2 TP + FP + FN)\n",
    "f1 = f1_score(Y_valid, Y_valid_predicted, average = 'macro')\n",
    "print('Macro F1 score: %f' % f1)\n",
    "\n",
    "# Compute Weighted metrics of the classifier\n",
    "precision = precision_score(Y_valid, Y_valid_predicted, average = 'weighted')\n",
    "print('Weighted Precision: %f' % precision)\n",
    "recall = recall_score(Y_valid, Y_valid_predicted, average = 'weighted')\n",
    "print('Weighted Recall: %f' % recall)\n",
    "f1 = f1_score(Y_valid, Y_valid_predicted, average = 'weighted')\n",
    "print('Weighted F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time of SVM classifier: 21.459 s\n",
      "Training accuracy:  0.6234949353379626\n",
      "Validation accuracy:  0.5993447993447993\n",
      "Macro Precision: 0.643060\n",
      "Macro Recall: 0.381768\n",
      "Macro F1 score: 0.347500\n",
      "Weighted Precision: 0.629982\n",
      "Weighted Recall: 0.607043\n",
      "Weighted F1 score: 0.504081\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# record time start running the model\n",
    "t0 = time.time()\n",
    "\n",
    "# SVM \n",
    "svm = SVC(kernel='linear', C=0.1).fit(X_var_train, Y_sub_train)\n",
    "\n",
    "# record time finished then minus the initial time to get the time consumed\n",
    "t1 = time.time() - t0\n",
    "print(\"Execution time of SVM classifier: {} s\".format(round(t1,3)))\n",
    "\n",
    "Y_train_predicted = svm.predict(X_var_train)\n",
    "print('Training accuracy: ', np.mean(Y_train_predicted == Y_sub_train))\n",
    "\n",
    "svm_acc = np.mean(cross_val_score(svm, X_var_valid, Y_valid, cv=5))\n",
    "print('Validation accuracy: ', svm_acc)\n",
    "\n",
    "# LR_label = lr.predict(X_var_test)\n",
    "# print(LR_label.shape)\n",
    "\n",
    "Y_valid_predicted = svm.predict(X_var_valid)\n",
    "\n",
    "# Compute Macro metrics of the classifier\n",
    "precision = precision_score(Y_valid, Y_valid_predicted, average = 'macro')\n",
    "print('Macro Precision: %f' % precision)\n",
    "\n",
    "# Recall = TP / (TP + FN)\n",
    "recall = recall_score(Y_valid, Y_valid_predicted, average = 'macro')\n",
    "print('Macro Recall: %f' % recall)\n",
    "\n",
    "# F1 = 2 TP / (2 TP + FP + FN)\n",
    "f1 = f1_score(Y_valid, Y_valid_predicted, average = 'macro')\n",
    "print('Macro F1 score: %f' % f1)\n",
    "\n",
    "# Compute Weighted metrics of the classifier\n",
    "precision = precision_score(Y_valid, Y_valid_predicted, average = 'weighted')\n",
    "print('Weighted Precision: %f' % precision)\n",
    "recall = recall_score(Y_valid, Y_valid_predicted, average = 'weighted')\n",
    "print('Weighted Recall: %f' % recall)\n",
    "f1 = f1_score(Y_valid, Y_valid_predicted, average = 'weighted')\n",
    "print('Weighted F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time of Random Forest classifier: 0.75 s\n",
      "Training accuracy:  0.585462190227432\n",
      "Validation accuracy:  0.5847665847665848\n",
      "Macro Precision: 0.413256\n",
      "Macro Recall: 0.336484\n",
      "Macro F1 score: 0.253716\n",
      "Weighted Precision: 0.507428\n",
      "Weighted Recall: 0.584930\n",
      "Weighted F1 score: 0.436165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\643944.STUDENT\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\643944.STUDENT\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# record time start running the model\n",
    "t0 = time.time()\n",
    "\n",
    "# Random Forest model\n",
    "rf = RandomForestClassifier(criterion = 'entropy', max_depth = 12, max_features = 'auto',\n",
    "    min_samples_leaf = 1, min_samples_split = 3, n_estimators = 100, random_state = 6).fit(X_var_train, Y_sub_train)\n",
    "\n",
    "# record time finished then minus the initial time to get the time consumed\n",
    "t1 = time.time() - t0\n",
    "print(\"Execution time of Random Forest classifier: {} s\".format(round(t1,3)))\n",
    "\n",
    "Y_train_predicted = rf.predict(X_var_train)\n",
    "print('Training accuracy: ', np.mean(Y_train_predicted == Y_sub_train))\n",
    "\n",
    "rf_acc = np.mean(cross_val_score(rf, X_var_valid, Y_valid, cv=5))\n",
    "print('Validation accuracy: ', rf_acc)\n",
    "\n",
    "# LR_label = lr.predict(X_var_test)\n",
    "# print(LR_label.shape)\n",
    "\n",
    "Y_valid_predicted = rf.predict(X_var_valid)\n",
    "\n",
    "# Compute Macro metrics of the classifier\n",
    "precision = precision_score(Y_valid, Y_valid_predicted, average = 'macro')\n",
    "print('Macro Precision: %f' % precision)\n",
    "\n",
    "# Recall = TP / (TP + FN)\n",
    "recall = recall_score(Y_valid, Y_valid_predicted, average = 'macro')\n",
    "print('Macro Recall: %f' % recall)\n",
    "\n",
    "# F1 = 2 TP / (2 TP + FP + FN)\n",
    "f1 = f1_score(Y_valid, Y_valid_predicted, average = 'macro')\n",
    "print('Macro F1 score: %f' % f1)\n",
    "\n",
    "# Compute Weighted metrics of the classifier\n",
    "precision = precision_score(Y_valid, Y_valid_predicted, average = 'weighted')\n",
    "print('Weighted Precision: %f' % precision)\n",
    "recall = recall_score(Y_valid, Y_valid_predicted, average = 'weighted')\n",
    "print('Weighted Recall: %f' % recall)\n",
    "f1 = f1_score(Y_valid, Y_valid_predicted, average = 'weighted')\n",
    "print('Weighted F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\643944.STUDENT\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(lr, X_var_valid, Y_valid, cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "counter = dict(collections.Counter(Y_train))\n",
    "Label = ['positive', 'neutral', 'negative']\n",
    "data = [counter[\"positive\"], counter[\"neutral\"], counter[\"negative\"]]\n",
    "\n",
    "plt.bar(Label, data)\n",
    "plt.title('Label distribution of the training set')\n",
    "plt.xlabel('Label type')\n",
    "plt.ylabel('Number of labels')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
